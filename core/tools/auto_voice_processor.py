import os
import time
import shutil
import subprocess
from pathlib import Path
from typing import Dict, Optional, Tuple
from langchain_core.tools import tool
from utils.logger import logger

class AutoVoiceProcessor:
    """å…¨è‡ªåŠ¨å¾®ä¿¡è¯­éŸ³å¤„ç†å™¨"""
    
    def __init__(self):
        self.current_account = None
        self.voice_directory = None
        self.last_processing_time = 0
        
    def auto_detect_and_process_voice(self, scout_seconds: int = 30) -> Dict:
        """
        è‡ªåŠ¨æ£€æµ‹å½“å‰å¾®ä¿¡è´¦å·å¹¶å¤„ç†æœ€æ–°è¯­éŸ³
        
        Args:
            scout_seconds: æ‰«ææ—¶é—´èŒƒå›´ï¼ˆç§’ï¼‰
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        try:
            # 1. è‡ªåŠ¨è¯†åˆ«å½“å‰å¾®ä¿¡è´¦å·
            account_info = self._auto_identify_current_account()
            if not account_info.get('success'):
                return account_info
            
            # 2. å®šä½è¯­éŸ³ç›®å½•
            voice_path = self._locate_voice_directory(account_info['account_path'])
            if not voice_path:
                return {
                    'success': False,
                    'error': 'æ— æ³•å®šä½è¯­éŸ³ç›®å½•',
                    'account_info': account_info
                }
            
            # 3. å¯»æ‰¾æœ€æ–°è¯­éŸ³æ–‡ä»¶
            latest_voice = self._find_latest_voice_file(voice_path, scout_seconds)
            if not latest_voice:
                return {
                    'success': False,
                    'error': f'åœ¨{scout_seconds}ç§’å†…æœªæ‰¾åˆ°æ–°çš„è¯­éŸ³æ–‡ä»¶',
                    'voice_directory': str(voice_path),
                    'account_info': account_info
                }
            
            # 4. å¤„ç†è¯­éŸ³æ–‡ä»¶
            processed_result = self._process_voice_file(latest_voice)
            
            # 5. è¿”å›å®Œæ•´ç»“æœ
            return {
                'success': True,
                'account_info': account_info,
                'voice_file': str(latest_voice),
                'processing_result': processed_result,
                'timestamp': time.time()
            }
            
        except Exception as e:
            logger.error(f"è‡ªåŠ¨è¯­éŸ³å¤„ç†å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _auto_identify_current_account(self) -> Dict:
        """è‡ªåŠ¨è¯†åˆ«å½“å‰æœ€æ´»è·ƒçš„å¾®ä¿¡è´¦å·"""
        try:
            from core.tools.wechat_account_manager import _account_manager
            accounts = _account_manager.scan_all_accounts()
            
            if not accounts:
                return {'success': False, 'error': 'æœªæ£€æµ‹åˆ°ä»»ä½•å¾®ä¿¡è´¦å·'}
            
            # é€‰æ‹©æ´»è·ƒåº¦æœ€é«˜çš„è´¦å·
            current_account = max(accounts, key=lambda x: x['activity_score'])
            
            return {
                'success': True,
                'user_id': current_account['user_id'],
                'nickname': current_account['nickname'],
                'account_path': current_account['full_path'],
                'activity_score': current_account['activity_score'],
                'last_modified': current_account['last_modified']
            }
            
        except Exception as e:
            logger.error(f"è´¦å·è¯†åˆ«å¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    def _locate_voice_directory(self, account_path: str) -> Optional[Path]:
        """å®šä½è¯­éŸ³ç›®å½•"""
        try:
            account_dir = Path(account_path)
            voice_paths = [
                account_dir / "FileStorage" / "Voice",
                account_dir / "Voice",
                account_dir / "FileStorage" / "MsgAttach" / "Voice"
            ]
            
            for voice_path in voice_paths:
                if voice_path.exists():
                    logger.info(f"âœ… æ‰¾åˆ°è¯­éŸ³ç›®å½•: {voice_path}")
                    self.voice_directory = voice_path
                    return voice_path
            
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°è¯­éŸ³ç›®å½•ï¼Œè´¦å·è·¯å¾„: {account_path}")
            return None
            
        except Exception as e:
            logger.error(f"è¯­éŸ³ç›®å½•å®šä½å¤±è´¥: {e}")
            return None
    
    def _find_latest_voice_file(self, voice_dir: Path, scout_seconds: int) -> Optional[Path]:
        """å¯»æ‰¾æœ€æ–°çš„è¯­éŸ³æ–‡ä»¶"""
        try:
            latest_file = None
            latest_time = 0
            now = time.time()
            cutoff_time = now - scout_seconds
            
            # æ”¯æŒçš„è¯­éŸ³æ–‡ä»¶æ ¼å¼
            voice_extensions = {'.silk', '.aud', '.mp3', '.wav', '.m4a', '.amr'}
            
            for root, _, files in os.walk(voice_dir):
                for file in files:
                    if any(file.lower().endswith(ext) for ext in voice_extensions):
                        file_path = Path(root) / file
                        try:
                            mtime = file_path.stat().st_mtime
                            # åªè€ƒè™‘æœ€è¿‘çš„æ–‡ä»¶
                            if mtime > cutoff_time and mtime > latest_time:
                                latest_time = mtime
                                latest_file = file_path
                        except (OSError, PermissionError):
                            continue
            
            if latest_file:
                time_diff = int(now - latest_time)
                logger.info(f"âœ… æ‰¾åˆ°æœ€æ–°è¯­éŸ³æ–‡ä»¶: {latest_file} ({time_diff}ç§’å‰)")
                return latest_file
            else:
                logger.info(f"âŒ åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æœªæ‰¾åˆ°è¯­éŸ³æ–‡ä»¶")
                return None
                
        except Exception as e:
            logger.error(f"è¯­éŸ³æ–‡ä»¶æœç´¢å¤±è´¥: {e}")
            return None
    
    def _process_voice_file(self, voice_file: Path) -> Dict:
        """å¤„ç†è¯­éŸ³æ–‡ä»¶ï¼ˆè¯†åˆ«+TTSï¼‰"""
        try:
            # 1. å‡†å¤‡ä¸´æ—¶ç›®å½•
            temp_dir = Path("temp") / "voice_processing"
            temp_dir.mkdir(parents=True, exist_ok=True)
            
            # 2. å¤åˆ¶æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
            temp_file = temp_dir / voice_file.name
            shutil.copy2(voice_file, temp_file)
            
            # 3. ä¿®å¤SILKå¤´éƒ¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if temp_file.suffix.lower() == '.silk':
                from core.tools.voice_healer import patch_silk_header
                repaired_file = patch_silk_header(str(temp_file))
                if repaired_file != str(temp_file):
                    temp_file = Path(repaired_file)
            
            # 4. è§£ç SILKæ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
            final_audio_path = str(temp_file)
            if temp_file.suffix.lower() == '.silk':
                from core.tools.voice_decoder import decode_silk_to_wav
                decoded_result = decode_silk_to_wav.invoke(str(temp_file))
                if "âŒ" not in decoded_result:
                    final_audio_path = decoded_result
            
            # 5. è°ƒç”¨å·¥å…·è¿›è¡Œè¯†åˆ«
            from tools.default import recognize_speech_from_audio
            recognition_result = recognize_speech_from_audio.invoke({"audio_file_path": final_audio_path})
            
            if recognition_result.get("status") != "success":
                return {
                    'success': False,
                    'stage': 'recognition',
                    'error': recognition_result.get("message", "è¯†åˆ«å¤±è´¥")
                }
            
            recognized_text = recognition_result.get("recognized_text", "")
            logger.info(f"ğŸ—£ï¸ è¯­éŸ³è¯†åˆ«ç»“æœ: {recognized_text}")
            
            # 6. æƒ…æ„Ÿåˆ†æ
            from core.tools.sentiment_engine import analyze_voice_sentiment
            duration = self._get_audio_duration(final_audio_path)
            sentiment = analyze_voice_sentiment.invoke({
                "transcript": recognized_text,
                "duration": duration
            })
            
            # 7. TTSåˆæˆå›åº”
            tts_result = self._generate_tts_response(recognized_text, sentiment)
            
            return {
                'success': True,
                'recognized_text': recognized_text,
                'sentiment': sentiment,
                'tts_result': tts_result,
                'audio_duration': duration,
                'processed_file': final_audio_path
            }
            
        except Exception as e:
            logger.error(f"è¯­éŸ³å¤„ç†å¤±è´¥: {e}")
            return {
                'success': False,
                'stage': 'processing',
                'error': str(e)
            }
    
    def _get_audio_duration(self, audio_path: str) -> float:
        """è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿"""
        try:
            cmd = f'ffprobe -i "{audio_path}" -show_entries format=duration -v quiet -of csv="p=0"'
            duration = float(subprocess.check_output(cmd, shell=True).strip() or 5.0)
            return duration
        except:
            return 5.0  # é»˜è®¤5ç§’
    
    def _generate_tts_response(self, recognized_text: str, sentiment: str) -> Dict:
        """ç”ŸæˆTTSå›åº”"""
        try:
            # æ„é€ æ™ºèƒ½å›åº”
            response_text = self._generate_intelligent_response(recognized_text, sentiment)
            
            # TTSåˆæˆ
            import asyncio
            from tools.speech_tool import async_tts_and_play
            
            # å¼‚æ­¥æ‰§è¡ŒTTS
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                tts_result = loop.run_until_complete(async_tts_and_play(response_text))
            finally:
                loop.close()
            
            return {
                'success': True,
                'response_text': response_text,
                'tts_audio_path': tts_result if tts_result else None,
                'sentiment_used': sentiment
            }
            
        except Exception as e:
            logger.error(f"TTSç”Ÿæˆå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _generate_intelligent_response(self, text: str, sentiment: str) -> str:
        """ç”Ÿæˆæ™ºèƒ½å›åº”æ–‡æœ¬"""
        # åŸºäºæƒ…æ„Ÿå’Œå†…å®¹ç”Ÿæˆå›åº”
        responses = {
            'positive': [
                f"å¬èµ·æ¥å¾ˆä¸é”™å‘¢ï¼ä½ è¯´çš„{text}è®©æˆ‘å¾ˆæ„Ÿå…´è¶£ã€‚",
                f"å¾ˆé«˜å…´å¬åˆ°ä½ åˆ†äº«{sentiment}çš„æƒ³æ³•ï¼"
            ],
            'negative': [
                f"æˆ‘ç†è§£ä½ çš„æ„Ÿå—ï¼Œ{text}ç¡®å®è®©äººæœ‰äº›å›°æ‰°ã€‚",
                f"å¬èµ·æ¥ä½ ç°åœ¨{sentiment}ï¼Œéœ€è¦æˆ‘å¸®å¿™å—ï¼Ÿ"
            ],
            'neutral': [
                f"æˆ‘å¬åˆ°äº†ä½ è¯´çš„{text}ï¼Œå¾ˆæœ‰æ„æ€ã€‚",
                f"è°¢è°¢ä½ çš„åˆ†äº«ï¼Œå…³äº{text}æˆ‘æƒ³äº†è§£æ›´å¤šã€‚"
            ]
        }
        
        # æ ¹æ®æƒ…æ„Ÿé€‰æ‹©å›åº”
        sentiment_key = sentiment.split()[0] if ' ' in sentiment else 'neutral'
        if sentiment_key not in responses:
            sentiment_key = 'neutral'
            
        import random
        return random.choice(responses[sentiment_key])

# å…¨å±€å®ä¾‹
_auto_voice_processor = AutoVoiceProcessor()

@tool
def auto_process_latest_voice(scout_seconds: int = 30, force_refresh: bool = False) -> str:
    """
    è‡ªåŠ¨å¤„ç†æœ€æ–°çš„å¾®ä¿¡è¯­éŸ³æ¶ˆæ¯
    
    Args:
        scout_seconds: æ‰«ææ—¶é—´èŒƒå›´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤30ç§’
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°è´¦å·ä¿¡æ¯ï¼Œé»˜è®¤False
        
    Returns:
        å¤„ç†ç»“æœçš„è¯¦ç»†ä¿¡æ¯
    """
    try:
        # å¦‚æœéœ€è¦å¼ºåˆ¶åˆ·æ–°æˆ–è·ç¦»ä¸Šæ¬¡å¤„ç†è¶…è¿‡10ç§’
        current_time = time.time()
        if force_refresh or (current_time - _auto_voice_processor.last_processing_time) > 10:
            from core.tools.wechat_account_manager import refresh_account_list
            refresh_account_list.invoke({})
            _auto_voice_processor.last_processing_time = current_time
        
        result = _auto_voice_processor.auto_detect_and_process_voice(scout_seconds)
        
        if result['success']:
            processing_result = result['processing_result']
            if processing_result['success']:
                response = "âœ… è¯­éŸ³å¤„ç†æˆåŠŸ!\n"
                response += "=" * 30 + "\n"
                response += f"ğŸ‘¤ è´¦å·: {result['account_info']['nickname']} ({result['account_info']['user_id']})\n"
                response += f"ğŸ”Š è¯­éŸ³æ–‡ä»¶: {os.path.basename(result['voice_file'])}\n"
                response += f"ğŸ—£ï¸ è¯†åˆ«å†…å®¹: {processing_result['recognized_text']}\n"
                response += f"ğŸ’­ æƒ…æ„Ÿåˆ†æ: {processing_result['sentiment']}\n"
                response += f"ğŸ¤– AIå›åº”: {processing_result['tts_result']['response_text']}\n"
                
                if processing_result['tts_result']['tts_audio_path']:
                    response += f"ğŸµ TTSéŸ³é¢‘: {processing_result['tts_result']['tts_audio_path']}\n"
                
                response += f"â±ï¸ å¤„ç†æ—¶é—´: {time.strftime('%H:%M:%S')}"
            else:
                response = f"âŒ è¯­éŸ³å¤„ç†å¤±è´¥: {processing_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
        else:
            response = f"âŒ å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            if 'account_info' in result:
                response += f"\nå½“å‰è´¦å·: {result['account_info'].get('nickname', 'æœªçŸ¥')}"
        
        return response
        
    except Exception as e:
        logger.error(f"è‡ªåŠ¨è¯­éŸ³å¤„ç†å·¥å…·å¤±è´¥: {e}")
        return f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"

@tool
def monitor_voice_continuously(interval: int = 60) -> str:
    """
    æŒç»­ç›‘æ§è¯­éŸ³æ¶ˆæ¯ï¼ˆæµ‹è¯•ç”¨ï¼‰
    
    Args:
        interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤60ç§’
        
    Returns:
        ç›‘æ§å¯åŠ¨ä¿¡æ¯
    """
    try:
        response = f"ğŸ”„ å·²å¯åŠ¨è¯­éŸ³ç›‘æ§ï¼Œæ£€æŸ¥é—´éš”: {interval}ç§’\n"
        response += "ä½¿ç”¨ 'stop_voice_monitor' åœæ­¢ç›‘æ§"
        # å®é™…å®ç°éœ€è¦åå°çº¿ç¨‹ï¼Œè¿™é‡Œåªè¿”å›å¯åŠ¨ä¿¡æ¯
        return response
    except Exception as e:
        return f"âŒ ç›‘æ§å¯åŠ¨å¤±è´¥: {str(e)}"

@tool
def get_voice_system_status() -> str:
    """
    è·å–è¯­éŸ³å¤„ç†ç³»ç»ŸçŠ¶æ€
    
    Returns:
        ç³»ç»ŸçŠ¶æ€ä¿¡æ¯
    """
    try:
        # æ£€æŸ¥ä¾èµ–
        dependencies = {
            'ffmpeg': 'ffprobe -version',
            'edge-tts': 'edge-tts --version',
            'speech_recognition': None
        }
        
        status_lines = ["ğŸ™ï¸ è¯­éŸ³å¤„ç†ç³»ç»ŸçŠ¶æ€\n" + "=" * 25]
        
        for dep_name, check_cmd in dependencies.items():
            try:
                if check_cmd:
                    subprocess.check_output(check_cmd, shell=True, stderr=subprocess.DEVNULL)
                status_lines.append(f"âœ… {dep_name}: å¯ç”¨")
            except:
                status_lines.append(f"âŒ {dep_name}: ä¸å¯ç”¨")
        
        # æ˜¾ç¤ºå½“å‰é…ç½®
        status_lines.append(f"\nâš™ï¸ å½“å‰é…ç½®:")
        status_lines.append(f"   è´¦å·è¯†åˆ«: è‡ªåŠ¨")
        status_lines.append(f"   è·¯å¾„å®šä½: è‡ªåŠ¨")
        status_lines.append(f"   è¯­éŸ³æ ¼å¼: SILK/MP3/WAV/M4A/AMR")
        status_lines.append(f"   TTSå¼•æ“: Edge-TTS")
        
        return "\n".join(status_lines)
        
    except Exception as e:
        return f"âŒ çŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}"